services:
  db:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-edtech}
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 5s
      timeout: 5s
      retries: 20

  code-runner:
    build:
      context: ./services/code-runner
    environment:
      RUN_TIMEOUT_SEC: ${RUN_TIMEOUT_SEC:-4}
      RUN_MEMORY_MB: ${RUN_MEMORY_MB:-128}
    ports:
      - "${CODE_RUNNER_PORT:-8100}:8100"

  ollama:
    image: ollama/ollama:latest
    container_name: ollama-server
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_NUM_GPU=0

  api:
    build:
      context: ./apps/api
    environment:
      APP_ENV: ${API_ENV:-development}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-edtech}
      POSTGRES_HOST: ${POSTGRES_HOST:-db}
      POSTGRES_PORT: ${POSTGRES_PORT:-5432}
      SECRET_KEY: ${API_SECRET_KEY:-change-this-in-prod}
      ACCESS_TOKEN_EXPIRE_MINUTES: ${ACCESS_TOKEN_EXPIRE_MINUTES:-10080}
      USE_OFFLINE_AI: ${USE_OFFLINE_AI:-true}
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL:-http://ollama:11434}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-mistral:latest}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      OPENAI_MODEL: ${OPENAI_MODEL:-openai/gpt-4-turbo}
      OPENAI_BASE_URL: ${OPENAI_BASE_URL:-https://openrouter.ai/api/v1}
      CODE_RUNNER_URL: ${CODE_RUNNER_URL:-http://code-runner:8100}
      STRIPE_SECRET_KEY: ${STRIPE_SECRET_KEY:-}
      STRIPE_WEBHOOK_SECRET: ${STRIPE_WEBHOOK_SECRET:-}
      STRIPE_PRICE_ID: ${STRIPE_PRICE_ID:-price_12345}
    ports:
      - "${API_PORT:-8000}:8000"
    depends_on:
      db:
        condition: service_healthy
      code-runner:
        condition: service_started
      ollama:
        condition: service_started

  web:
    build:
      context: ./apps/web
    environment:
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-/api}
      API_INTERNAL_URL: ${API_INTERNAL_URL:-http://api:8000}
    ports:
      - "${WEB_PORT:-3000}:3000"
    depends_on:
      - api

volumes:
  pgdata:
  ollama_data:
